# -*- coding: utf-8 -*-
"""Superresolution01_Swin_Tiny.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uQv4KNVlYmEYRs3eYOhfet2v_ve7ZNAt
"""

!pip install timm

import timm
from torchvision.transforms import Resize
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models, transforms
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from PIL import Image
from torch.utils.data import Dataset
from torch.optim.lr_scheduler import StepLR
import matplotlib.pyplot as plt
import numpy as np
from google.colab import drive
drive.mount('/content/drive')

def compute_mean_std(dataloader):
    mean = 0.
    std = 0.
    nb_samples = 0.
    for data, _ in dataloader:
        batch_samples = data.size(0)
        data = data.view(batch_samples, data.size(1), -1)
        mean += data.mean(2).sum(0)
        std += data.std(2).sum(0)
        nb_samples += batch_samples

    mean /= nb_samples
    std /= nb_samples
    return mean, std

# Define the device to use for training
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class SuperResolutionDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform=None):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.transform = transform
        self.image_filenames = [os.path.join(lr_dir, f) for f in os.listdir(lr_dir) if f.endswith('.png')]

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, index):
        lr_image_filename = self.image_filenames[index]
        hr_image_filename = os.path.join(self.hr_dir, os.path.basename(lr_image_filename))
        lr_image = Image.open(lr_image_filename)
        hr_image = Image.open(hr_image_filename)

       
        if self.transform:
           lr_image = self.transform(lr_image)
           hr_image = self.transform(hr_image)
        return lr_image, hr_image



temp_transform = transforms.Compose([
    Resize((224, 224)),
    transforms.ToTensor()
])

temp_train_dataset = SuperResolutionDataset('/content/drive/My Drive/Liang/SuperResolution01/train/low', '/content/drive/My Drive/Liang/SuperResolution01/train/org', transform=temp_transform)
temp_train_dataloader = DataLoader(temp_train_dataset, batch_size=4, shuffle=True)

mean, std = compute_mean_std(temp_train_dataloader)
print("Mean:", mean)
print("Std:", std)


# Update the transformation to include image resizing
lr_transform = transforms.Compose([
    Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean, std=std)
])

hr_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=mean, std=std)
])


class SwinSuperResolution(nn.Module):
    def __init__(self):
        super(SwinSuperResolution, self).__init__()

        base_model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)
        base_model.conv1 = nn.Conv2d(3, 96, kernel_size=4, stride=2, padding=1, bias=False)

        self.features = nn.Sequential(*list(base_model.children())[:-2])

        self.upconv1 = nn.Sequential(
            nn.ConvTranspose2d(96, 48, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv2 = nn.Sequential(
            nn.ConvTranspose2d(48, 24, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv3 = nn.Sequential(
            nn.ConvTranspose2d(24, 12, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv4 = nn.Sequential(
            nn.ConvTranspose2d(12, 12, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv5 = nn.Sequential(
            nn.ConvTranspose2d(12, 3, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )


    def forward(self, x):
        x = self.features(x)
        x = self.upconv1(x)
        x = self.upconv2(x)
        x = self.upconv3(x)
        x = self.upconv4(x)
        x = self.upconv5(x)  # Add this line
        return x


# Define the SwinTinySuperResolution model
model = SwinSuperResolution()

# Define the training and test datasets and dataloaders
train_dataset = SuperResolutionDataset('/content/drive/My Drive/Liang/SuperResolution01_RGB/train/low', '/content/drive/My Drive/Liang/SuperResolution01_RGB/train/org', transform=lr_transform)
test_dataset = SuperResolutionDataset('/content/drive/My Drive/Liang/SuperResolution01_RGB/test/low', '/content/drive/My Drive/Liang/SuperResolution01_RGB/test/org', transform=lr_transform)

train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Define the loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Add the learning rate scheduler
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

# Train the model
train_losses = []
test_losses = []

num_batches = len(train_dataloader)

for epoch in range(50):
    running_loss = 0.0
    for i, (batch_images, batch_labels) in enumerate(train_dataloader):
        # Transfer the batch to the device
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        model.to(device)
        batch_images = batch_images.to(device)
        batch_labels = batch_labels.to(device)

        optimizer.zero_grad()
        outputs = model(batch_images)
        loss = criterion(outputs, batch_labels.float())
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    train_loss = running_loss / num_batches

    # Add the scheduler step after each training epoch
    scheduler.step()


    # Evaluate the model on the test set
    test_loss = 0.0
    num_images = 0
    total_psnr = 0.0
    total_ssim = 0.0
    for test_images, test_labels in test_dataloader:
        # Move inputs and labels to the device
        test_images = test_images.to(device)
        test_labels = test_labels.to(device)

        # Forward pass
        test_outputs = model(test_images)
        test_loss += criterion(test_outputs, test_labels.unsqueeze(1).float()).item()

        # Calculate PSNR and SSIM
        mse = ((test_outputs - test_labels) ** 2).mean()
        psnr = 20 * torch.log10(torch.max(test_labels)) - 10 * torch.log10(torch.mean(mse))

        # Convert 3D tensors to 3D numpy arrays
        test_labels_3D = test_labels.squeeze(dim=0).cpu().numpy().transpose(1, 2, 0)
        test_outputs_3D = test_outputs.squeeze(dim=0).cpu().detach().numpy().transpose(1, 2, 0)

        # Calculate SSIM
        ssim = structural_similarity(test_labels_3D, test_outputs_3D, data_range=1.0, multichannel=True)


        # Update evaluation metrics
        num_images += 1
        total_psnr += psnr
        total_ssim += ssim

    test_loss /= len(test_dataloader)
    test_psnr = total_psnr / num_images
    test_ssim = total_ssim / num_images

    # Print the losses and evaluation metrics for this epoch
    print(f"Epoch {epoch+1}: Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}, Test PSNR: {test_psnr:.2f}, Test SSIM: {test_ssim:.4f}")
    train_losses.append(train_loss)
    test_losses.append(test_loss)

def display_images(lr_image, hr_image, sr_image, image_id):
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(lr_image, cmap='gray')
    axes[0].set_title(f'Low-Res Image (ID: {image_id})')
    axes[1].imshow(hr_image, cmap='gray')
    axes[1].set_title(f'High-Res Image (ID: {image_id})')
    axes[2].imshow(sr_image, cmap='gray')
    axes[2].set_title(f'Super-Res Image (ID: {image_id})')

    for ax in axes:
        ax.set_xticks([])
        ax.set_yticks([])

    plt.show()

# Choose a number of images to display
num_images_to_display = 5

for i, (test_images, test_labels) in enumerate(test_dataloader):
    if i >= num_images_to_display:
        break

    test_images = test_images.to(device)
    test_labels = test_labels.to(device)

    # Generate super-resolution images
    sr_images = model(test_images)

    # Convert images back to the original scale
    test_images = (test_images.squeeze().cpu().numpy() * 0.5) + 0.5
    test_labels = (test_labels.squeeze().cpu().numpy() * 0.5) + 0.5
    sr_images = (sr_images.squeeze().cpu().detach().numpy() * 0.5) + 0.5

    # Extract image ID from the filename
    image_id = os.path.splitext(os.path.basename(test_dataset.image_filenames[i]))[0]

    # Display images along with their Image IDs
    display_images(test_images, test_labels, sr_images, image_id)