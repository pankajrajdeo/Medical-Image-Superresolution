# -*- coding: utf-8 -*-
"""Superresolution01_Resnet-18

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g7FPW1UX0zyoHhdED4I7q-xN8j_qm6Rt
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models, transforms
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from PIL import Image
from torch.utils.data import Dataset
from torch.optim.lr_scheduler import StepLR
import matplotlib.pyplot as plt
import numpy as np
from google.colab import drive
drive.mount('/content/drive')


# Define the device to use for training
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the transformation to apply to the images
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

class SuperResolutionDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform=None):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.transform = transform
        self.image_filenames = [os.path.join(lr_dir, f) for f in os.listdir(lr_dir) if f.endswith('.png')]

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, index):
        lr_image_filename = self.image_filenames[index]
        hr_image_filename = os.path.join(self.hr_dir, os.path.basename(lr_image_filename))
        lr_image = Image.open(lr_image_filename).convert('L') # Convert to grayscale
        hr_image = Image.open(hr_image_filename).convert('L')
        if self.transform:
            lr_image = self.transform(lr_image)
            hr_image = self.transform(hr_image)
        return lr_image, hr_image

class ResNetSuperResolution(nn.Module):
    def __init__(self):
        super(ResNetSuperResolution, self).__init__()

        base_model = models.resnet18(pretrained=True)
        base_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)

        self.features = nn.Sequential(*list(base_model.children())[:-2])

        self.upconv1 = nn.Sequential(
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv2 = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv3 = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv4 = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )
        self.upconv5 = nn.Sequential(
            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True)
        )


    def forward(self, x):
        x = self.features(x)
        x = self.upconv1(x)
        x = self.upconv2(x)
        x = self.upconv3(x)
        x = self.upconv4(x)
        x = self.upconv5(x)  # Add this line
        return x


# Define the training and test datasets and dataloaders
train_dataset = SuperResolutionDataset('/content/drive/My Drive/Liang/SuperResolution01/train/low', '/content/drive/My Drive/Liang/SuperResolution01/train/org', transform=transform)
test_dataset = SuperResolutionDataset('/content/drive/My Drive/Liang/SuperResolution01/test/low', '/content/drive/My Drive/Liang/SuperResolution01/test/org', transform=transform)

train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)


# Define the ResNetSuperResolution model
model = ResNetSuperResolution()


# Define the loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Add the learning rate scheduler
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)


# Train the model
train_losses = []
test_losses = []

num_batches = len(train_dataloader)

for epoch in range(50):
    running_loss = 0.0
    for i, (batch_images, batch_labels) in enumerate(train_dataloader):
        # Transfer the batch to the device
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        model.to(device)
        batch_images = batch_images.to(device)
        batch_labels = batch_labels.to(device)

        optimizer.zero_grad()
        outputs = model(batch_images)
        loss = criterion(outputs, batch_labels.float())
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    train_loss = running_loss / num_batches

    # Add the scheduler step after each training epoch
    scheduler.step(test_loss)


    # Evaluate the model on the test set
    test_loss = 0.0
    num_images = 0
    total_psnr = 0.0
    total_ssim = 0.0
    for test_images, test_labels in test_dataloader:
        # Move inputs and labels to the device
        test_images = test_images.to(device)
        test_labels = test_labels.to(device)

        # Forward pass
        test_outputs = model(test_images)
        test_loss += criterion(test_outputs, test_labels.unsqueeze(1).float()).item()

        # Calculate PSNR and SSIM
        mse = ((test_outputs - test_labels) ** 2).mean()
        psnr = 20 * torch.log10(torch.max(test_labels)) - 10 * torch.log10(torch.mean(mse))
        ssim = structural_similarity(test_labels.squeeze().cpu().numpy(), test_outputs.squeeze().cpu().detach().numpy(), data_range=1.0)

        # Update evaluation metrics
        num_images += 1
        total_psnr += psnr
        total_ssim += ssim

        test_loss /= len(test_dataloader)
        test_psnr = total_psnr / num_images
        test_ssim = total_ssim / num_images

# Print the losses and evaluation metrics for this epoch
print(f"Epoch {epoch+1}: Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}, Test PSNR: {test_psnr:.2f}, Test SSIM: {test_ssim:.4f}")
train_losses.append(train_loss)
test_losses.append(test_loss)

def display_images(lr_image, hr_image, sr_image, image_id):
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(lr_image, cmap='gray')
    axes[0].set_title(f'Low-Res Image (ID: {image_id})')
    axes[1].imshow(hr_image, cmap='gray')
    axes[1].set_title(f'High-Res Image (ID: {image_id})')
    axes[2].imshow(sr_image, cmap='gray')
    axes[2].set_title(f'Super-Res Image (ID: {image_id})')

    for ax in axes:
        ax.set_xticks([])
        ax.set_yticks([])

    plt.show()

# Choose a number of images to display
num_images_to_display = 5

for i, (test_images, test_labels) in enumerate(test_dataloader):
    if i >= num_images_to_display:
        break

    test_images = test_images.to(device)
    test_labels = test_labels.to(device)

    # Generate super-resolution images
    sr_images = model(test_images)

    # Convert images back to the original scale
    test_images = (test_images.squeeze().cpu().numpy() * 0.5) + 0.5
    test_labels = (test_labels.squeeze().cpu().numpy() * 0.5) + 0.5
    sr_images = (sr_images.squeeze().cpu().detach().numpy() * 0.5) + 0.5

    # Extract image ID from the filename
    image_id = os.path.splitext(os.path.basename(test_dataset.image_filenames[i]))[0]

    # Display images along with their Image IDs
    display_images(test_images, test_labels, sr_images, image_id)